Process for testing our project:

Frameworks being used:
Language: Python3
Unit Testing Framework: unittest
Code Coverage Framework: Coverage.py
    pipenv run python -m coverage run -m unittest discover
    This will run all of them, if you want to run a single file replace discover with the path to the file from the project level
    coverage report. For example, to run test_amazon with coverage , use the following command: python3 -m coverage run -m unittest test/test_amazon.py 
    Command to generate html report to see which lines are being covered: coverage html
        The html report can be found in the folder htmlcov

Mutation Testing Framework: PyMut
    Instructions for mutation Testing:

    Generate mutants:
    mut.py --target stores/amazon.py --unit-test test/mock_amazon.py -m
    Generate mutation report: 
    mut.py --target stores/amazon.py --unit-test test/mock_amazon.py -m --report-html DIR_NAME

Instructions for testing:
Install packages using the following commands (while in top level project directory):
pipenv install
pipenv run python -m coverage run -m unittest discover
Follow the instructions to initialize your Credential File Password 
Note: the amazon account you are using should have an empty cart before running tests. If you don’t want to use your own amazon account we created a test account with the follow credentials:
Username: rsashti1@jhu.edu 
Password: swtisthebest
Re-run the tests, you will need to re-enter in your password for the credential file for every test
WARNING: you must wait until the chromedriver window closes on its own and for the next password prompt pops up or else you risk a collision of two threads accessing the encrypted password config file (amazon_config.json) at the same time
SO either wait for the chrome window to close, or if the next password thread pops up before the chrome window closes, close the chrome window MANUALLY and then continue on typing your password


RESULTS:
    Through our tests, we wanted to achieve solid code coverage. We were able to achieve a final code coverage 
after all of our tests is 41%. 
    As we mentioend in the presentation, much of the reason why it's not possible to attain high coverage is because
quite a lot of the code is split into try/except blocks, that get triggered by very obscure examples/edge cases 
that we could not replicate. Another reason is because some of the code is very tightly coupled to the Chrome driver
framework which made it difficult to reach those parts.

Limitations:
    We weren’t able to invest money into a subscription for an Amazon Prime account, so we made a free test account to work with. Because of this, we had to stop our tests at the enter address screen, as Fairgame is programmed to work with a default address. 
For a similar reason, also weren’t able to test any methods that dealt with order 
Had to input password everytime we ran a test because of password-locked information
    In terms of testing, we weren't able to exhaustively generate each mutant. The reason is because the speed at which 
the tests run since each has to open a chrome generator and each pyMut that is generated must be run against each and every
test case, the resulting amount of computations was way too big for our computational power.

